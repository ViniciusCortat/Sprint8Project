{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "754e146e",
   "metadata": {},
   "source": [
    "# Importando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95291e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1623566b",
   "metadata": {},
   "source": [
    "# Inicializando DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cbe27a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ebcb45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0   40.0   311.90      83.0  19915.42         0\n",
      "1   85.0   516.75      56.0  22696.96         0\n",
      "2   77.0   467.66      86.0  21060.45         0\n",
      "3  106.0   745.53      81.0   8437.39         1\n",
      "4   66.0   418.74       1.0  14502.75         0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c405c7e9",
   "metadata": {},
   "source": [
    "# Desenvolvimento do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7662a75d",
   "metadata": {},
   "source": [
    "### Criando as respectivas features e targets para treinamento e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d26c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = df.drop('is_ultra', axis=1)\n",
    "target = df['is_ultra']\n",
    "\n",
    "feature_train, feature_valid, target_train, target_valid = train_test_split(feature, target, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c274a",
   "metadata": {},
   "source": [
    "## Treinando os modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6216540b",
   "metadata": {},
   "source": [
    "### Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b652e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia pelo modelo de regressão logística: 0.7027363184079602\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "logistic_model.fit(feature_train, target_train)\n",
    "\n",
    "logistic_prediction = logistic_model.predict(feature_valid)\n",
    "logistic_accuracy = accuracy_score(target_valid, logistic_prediction)\n",
    "print('Acurácia pelo modelo de regressão logística:', logistic_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d686b482",
   "metadata": {},
   "source": [
    "<span style='color:red'> No modelo de regressão logística obtivemos o valor de 0.70 indicando que 70% dos valores estavam corretos, espera-se que este seja o pior modelo que está inclusive abaixo do limite de 0.75, dito isso foi fácil de implementar e o resultado foi gerado rapidamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7733c12",
   "metadata": {},
   "source": [
    "### Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58ef4ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia pelo modelo de árvore de decisão: 0.7898009950248757 com depth de 7\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0.75\n",
    "best_tree_depth = 0\n",
    "for depth in range(1, 10):\n",
    "    decision_tree_model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    decision_tree_model.fit(feature_train, target_train)\n",
    "\n",
    "    decision_tree_prediction = decision_tree_model.predict(feature_valid)\n",
    "    current_accuracy = accuracy_score(target_valid, decision_tree_prediction)\n",
    "    if current_accuracy > best_accuracy:\n",
    "        best_accuracy = current_accuracy\n",
    "        best_tree_depth = depth\n",
    "decision_tree_accuracy = best_accuracy\n",
    "print(f'Acurácia pelo modelo de árvore de decisão: {decision_tree_accuracy} com depth de {best_tree_depth}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3351bdd1",
   "metadata": {},
   "source": [
    "<span style='color:red'> No modelo de árvore de decisão o resultado foi de 0.79, ou seja, 79% dos valores estavam corretos, acima do limite, precisa de mais tempo para encontrar o depth ideal mas ainda foi relativamente rapido de gerar resultado. OBS: o depth foi testado com valores até 50 mas 7 sempre foi o depth com melhor ácuracia, portanto reduzi para 10 pra poder rodar o código mais rapido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7abd9f",
   "metadata": {},
   "source": [
    "### Floresta Aleatória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48472024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia pelo modelo de floresta aleatória: 0.8146766169154229 com depth de 9 e n_estimators de 19\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0.75\n",
    "best_forest_depth = 0\n",
    "best_n_estimators = 1\n",
    "for depth in range(1, 10):\n",
    "    for n in range(1, 20):\n",
    "        random_forest_model = RandomForestClassifier(random_state=12345, max_depth=depth, n_estimators=n)\n",
    "        random_forest_model.fit(feature_train, target_train)\n",
    "\n",
    "        random_forest_prediction = random_forest_model.predict(feature_valid)\n",
    "        current_accuracy = accuracy_score(target_valid, random_forest_prediction)\n",
    "        if current_accuracy > best_accuracy:\n",
    "            best_accuracy = current_accuracy\n",
    "            best_forest_depth = depth\n",
    "            best_n_estimators = n\n",
    "random_forest_accuracy = best_accuracy\n",
    "print(f'Acurácia pelo modelo de floresta aleatória: {random_forest_accuracy} com depth de {best_forest_depth} e n_estimators de {best_n_estimators}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04c23fa",
   "metadata": {},
   "source": [
    "<span style='color:red'> No modelo de floresta aleatória obtivemos 81% de acurácia, o melhor resultado entre os 3 modelos testados, este modelo já precisou de mais tempo para encontrar não só o depth ideal mas o n_estimator ideal também, que gerou mais custo computacional. OBS: Os valores de depth iam até 20 e o n_estimators até 50 originalmente mas o melhor valor encontrado foi depth 9 com n_estimators 19, com isso eu reduzi os valores para que rodasse mais rápido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f7eb50",
   "metadata": {},
   "source": [
    "## Comparação Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ea7671c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia pelo modelo de regressão logística: 0.7027363184079602\n",
      "Acurácia pelo modelo de árvore de decisão: 0.7898009950248757 com depth de 7\n",
      "Acurácia pelo modelo de floresta aleatória: 0.8146766169154229 com depth de 9 e n_estimators de 19\n"
     ]
    }
   ],
   "source": [
    "print('Acurácia pelo modelo de regressão logística:', logistic_accuracy)\n",
    "print(f'Acurácia pelo modelo de árvore de decisão: {decision_tree_accuracy} com depth de {best_tree_depth}')\n",
    "print(f'Acurácia pelo modelo de floresta aleatória: {random_forest_accuracy} com depth de {best_forest_depth} e n_estimators de {best_n_estimators}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7d119c",
   "metadata": {},
   "source": [
    "# Prova Real dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b02cb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_ultra\n",
       "0    0.693528\n",
       "1    0.306472\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_ultra'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38621e63",
   "metadata": {},
   "source": [
    "<span style='color:red'> 30.65% dos usuários são ultra, significa que se classificarmos todos os usuários como não ultra, teriamos 69.35% de acurácia, o que significa que todos os modelos são melhores do que se classificarmos ao acaso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee75210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
